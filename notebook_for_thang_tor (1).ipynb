{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#import sys\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import scipy\n",
    "#import code\n",
    "\n",
    "#import tensorflow.python.platform\n",
    "\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "\n",
    "# Dir for train\n",
    "data_dir = \"../data/training/\"\n",
    "train_data_filename = data_dir + 'images/'\n",
    "train_labels_filename = data_dir + 'groundtruth/' \n",
    "\n",
    "\n",
    "# Dir for test\n",
    "root_dir = \"../data/test_set_images/\"\n",
    "\n",
    "TRAINING_SIZE = 100\n",
    "TEST_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data/training/images/satImage_001.png\n",
      "Loading ../data/training/images/satImage_002.png\n",
      "Loading ../data/training/images/satImage_003.png\n",
      "Loading ../data/training/images/satImage_004.png\n",
      "Loading ../data/training/images/satImage_005.png\n",
      "Loading ../data/training/images/satImage_006.png\n",
      "Loading ../data/training/images/satImage_007.png\n",
      "Loading ../data/training/images/satImage_008.png\n",
      "Loading ../data/training/images/satImage_009.png\n",
      "Loading ../data/training/images/satImage_010.png\n",
      "Loading ../data/training/images/satImage_011.png\n",
      "Loading ../data/training/images/satImage_012.png\n",
      "Loading ../data/training/images/satImage_013.png\n",
      "Loading ../data/training/images/satImage_014.png\n",
      "Loading ../data/training/images/satImage_015.png\n",
      "Loading ../data/training/images/satImage_016.png\n",
      "Loading ../data/training/images/satImage_017.png\n",
      "Loading ../data/training/images/satImage_018.png\n",
      "Loading ../data/training/images/satImage_019.png\n",
      "Loading ../data/training/images/satImage_020.png\n",
      "Loading ../data/training/images/satImage_021.png\n",
      "Loading ../data/training/images/satImage_022.png\n",
      "Loading ../data/training/images/satImage_023.png\n",
      "Loading ../data/training/images/satImage_024.png\n",
      "Loading ../data/training/images/satImage_025.png\n",
      "Loading ../data/training/images/satImage_026.png\n",
      "Loading ../data/training/images/satImage_027.png\n",
      "Loading ../data/training/images/satImage_028.png\n",
      "Loading ../data/training/images/satImage_029.png\n",
      "Loading ../data/training/images/satImage_030.png\n",
      "Loading ../data/training/images/satImage_031.png\n",
      "Loading ../data/training/images/satImage_032.png\n",
      "Loading ../data/training/images/satImage_033.png\n",
      "Loading ../data/training/images/satImage_034.png\n",
      "Loading ../data/training/images/satImage_035.png\n",
      "Loading ../data/training/images/satImage_036.png\n",
      "Loading ../data/training/images/satImage_037.png\n",
      "Loading ../data/training/images/satImage_038.png\n",
      "Loading ../data/training/images/satImage_039.png\n",
      "Loading ../data/training/images/satImage_040.png\n",
      "Loading ../data/training/images/satImage_041.png\n",
      "Loading ../data/training/images/satImage_042.png\n",
      "Loading ../data/training/images/satImage_043.png\n",
      "Loading ../data/training/images/satImage_044.png\n",
      "Loading ../data/training/images/satImage_045.png\n",
      "Loading ../data/training/images/satImage_046.png\n",
      "Loading ../data/training/images/satImage_047.png\n",
      "Loading ../data/training/images/satImage_048.png\n",
      "Loading ../data/training/images/satImage_049.png\n",
      "Loading ../data/training/images/satImage_050.png\n",
      "Loading ../data/training/images/satImage_051.png\n",
      "Loading ../data/training/images/satImage_052.png\n",
      "Loading ../data/training/images/satImage_053.png\n",
      "Loading ../data/training/images/satImage_054.png\n",
      "Loading ../data/training/images/satImage_055.png\n",
      "Loading ../data/training/images/satImage_056.png\n",
      "Loading ../data/training/images/satImage_057.png\n",
      "Loading ../data/training/images/satImage_058.png\n",
      "Loading ../data/training/images/satImage_059.png\n",
      "Loading ../data/training/images/satImage_060.png\n",
      "Loading ../data/training/images/satImage_061.png\n",
      "Loading ../data/training/images/satImage_062.png\n",
      "Loading ../data/training/images/satImage_063.png\n",
      "Loading ../data/training/images/satImage_064.png\n",
      "Loading ../data/training/images/satImage_065.png\n",
      "Loading ../data/training/images/satImage_066.png\n",
      "Loading ../data/training/images/satImage_067.png\n",
      "Loading ../data/training/images/satImage_068.png\n",
      "Loading ../data/training/images/satImage_069.png\n",
      "Loading ../data/training/images/satImage_070.png\n",
      "Loading ../data/training/images/satImage_071.png\n",
      "Loading ../data/training/images/satImage_072.png\n",
      "Loading ../data/training/images/satImage_073.png\n",
      "Loading ../data/training/images/satImage_074.png\n",
      "Loading ../data/training/images/satImage_075.png\n",
      "Loading ../data/training/images/satImage_076.png\n",
      "Loading ../data/training/images/satImage_077.png\n",
      "Loading ../data/training/images/satImage_078.png\n",
      "Loading ../data/training/images/satImage_079.png\n",
      "Loading ../data/training/images/satImage_080.png\n",
      "Loading ../data/training/images/satImage_081.png\n",
      "Loading ../data/training/images/satImage_082.png\n",
      "Loading ../data/training/images/satImage_083.png\n",
      "Loading ../data/training/images/satImage_084.png\n",
      "Loading ../data/training/images/satImage_085.png\n",
      "Loading ../data/training/images/satImage_086.png\n",
      "Loading ../data/training/images/satImage_087.png\n",
      "Loading ../data/training/images/satImage_088.png\n",
      "Loading ../data/training/images/satImage_089.png\n",
      "Loading ../data/training/images/satImage_090.png\n",
      "Loading ../data/training/images/satImage_091.png\n",
      "Loading ../data/training/images/satImage_092.png\n",
      "Loading ../data/training/images/satImage_093.png\n",
      "Loading ../data/training/images/satImage_094.png\n",
      "Loading ../data/training/images/satImage_095.png\n",
      "Loading ../data/training/images/satImage_096.png\n",
      "Loading ../data/training/images/satImage_097.png\n",
      "Loading ../data/training/images/satImage_098.png\n",
      "Loading ../data/training/images/satImage_099.png\n",
      "Loading ../data/training/images/satImage_100.png\n",
      "Loading ../data/training/groundtruth/satImage_001.png\n",
      "Loading ../data/training/groundtruth/satImage_002.png\n",
      "Loading ../data/training/groundtruth/satImage_003.png\n",
      "Loading ../data/training/groundtruth/satImage_004.png\n",
      "Loading ../data/training/groundtruth/satImage_005.png\n",
      "Loading ../data/training/groundtruth/satImage_006.png\n",
      "Loading ../data/training/groundtruth/satImage_007.png\n",
      "Loading ../data/training/groundtruth/satImage_008.png\n",
      "Loading ../data/training/groundtruth/satImage_009.png\n",
      "Loading ../data/training/groundtruth/satImage_010.png\n",
      "Loading ../data/training/groundtruth/satImage_011.png\n",
      "Loading ../data/training/groundtruth/satImage_012.png\n",
      "Loading ../data/training/groundtruth/satImage_013.png\n",
      "Loading ../data/training/groundtruth/satImage_014.png\n",
      "Loading ../data/training/groundtruth/satImage_015.png\n",
      "Loading ../data/training/groundtruth/satImage_016.png\n",
      "Loading ../data/training/groundtruth/satImage_017.png\n",
      "Loading ../data/training/groundtruth/satImage_018.png\n",
      "Loading ../data/training/groundtruth/satImage_019.png\n",
      "Loading ../data/training/groundtruth/satImage_020.png\n",
      "Loading ../data/training/groundtruth/satImage_021.png\n",
      "Loading ../data/training/groundtruth/satImage_022.png\n",
      "Loading ../data/training/groundtruth/satImage_023.png\n",
      "Loading ../data/training/groundtruth/satImage_024.png\n",
      "Loading ../data/training/groundtruth/satImage_025.png\n",
      "Loading ../data/training/groundtruth/satImage_026.png\n",
      "Loading ../data/training/groundtruth/satImage_027.png\n",
      "Loading ../data/training/groundtruth/satImage_028.png\n",
      "Loading ../data/training/groundtruth/satImage_029.png\n",
      "Loading ../data/training/groundtruth/satImage_030.png\n",
      "Loading ../data/training/groundtruth/satImage_031.png\n",
      "Loading ../data/training/groundtruth/satImage_032.png\n",
      "Loading ../data/training/groundtruth/satImage_033.png\n",
      "Loading ../data/training/groundtruth/satImage_034.png\n",
      "Loading ../data/training/groundtruth/satImage_035.png\n",
      "Loading ../data/training/groundtruth/satImage_036.png\n",
      "Loading ../data/training/groundtruth/satImage_037.png\n",
      "Loading ../data/training/groundtruth/satImage_038.png\n",
      "Loading ../data/training/groundtruth/satImage_039.png\n",
      "Loading ../data/training/groundtruth/satImage_040.png\n",
      "Loading ../data/training/groundtruth/satImage_041.png\n",
      "Loading ../data/training/groundtruth/satImage_042.png\n",
      "Loading ../data/training/groundtruth/satImage_043.png\n",
      "Loading ../data/training/groundtruth/satImage_044.png\n",
      "Loading ../data/training/groundtruth/satImage_045.png\n",
      "Loading ../data/training/groundtruth/satImage_046.png\n",
      "Loading ../data/training/groundtruth/satImage_047.png\n",
      "Loading ../data/training/groundtruth/satImage_048.png\n",
      "Loading ../data/training/groundtruth/satImage_049.png\n",
      "Loading ../data/training/groundtruth/satImage_050.png\n",
      "Loading ../data/training/groundtruth/satImage_051.png\n",
      "Loading ../data/training/groundtruth/satImage_052.png\n",
      "Loading ../data/training/groundtruth/satImage_053.png\n",
      "Loading ../data/training/groundtruth/satImage_054.png\n",
      "Loading ../data/training/groundtruth/satImage_055.png\n",
      "Loading ../data/training/groundtruth/satImage_056.png\n",
      "Loading ../data/training/groundtruth/satImage_057.png\n",
      "Loading ../data/training/groundtruth/satImage_058.png\n",
      "Loading ../data/training/groundtruth/satImage_059.png\n",
      "Loading ../data/training/groundtruth/satImage_060.png\n",
      "Loading ../data/training/groundtruth/satImage_061.png\n",
      "Loading ../data/training/groundtruth/satImage_062.png\n",
      "Loading ../data/training/groundtruth/satImage_063.png\n",
      "Loading ../data/training/groundtruth/satImage_064.png\n",
      "Loading ../data/training/groundtruth/satImage_065.png\n",
      "Loading ../data/training/groundtruth/satImage_066.png\n",
      "Loading ../data/training/groundtruth/satImage_067.png\n",
      "Loading ../data/training/groundtruth/satImage_068.png\n",
      "Loading ../data/training/groundtruth/satImage_069.png\n",
      "Loading ../data/training/groundtruth/satImage_070.png\n",
      "Loading ../data/training/groundtruth/satImage_071.png\n",
      "Loading ../data/training/groundtruth/satImage_072.png\n",
      "Loading ../data/training/groundtruth/satImage_073.png\n",
      "Loading ../data/training/groundtruth/satImage_074.png\n",
      "Loading ../data/training/groundtruth/satImage_075.png\n",
      "Loading ../data/training/groundtruth/satImage_076.png\n",
      "Loading ../data/training/groundtruth/satImage_077.png\n",
      "Loading ../data/training/groundtruth/satImage_078.png\n",
      "Loading ../data/training/groundtruth/satImage_079.png\n",
      "Loading ../data/training/groundtruth/satImage_080.png\n",
      "Loading ../data/training/groundtruth/satImage_081.png\n",
      "Loading ../data/training/groundtruth/satImage_082.png\n",
      "Loading ../data/training/groundtruth/satImage_083.png\n",
      "Loading ../data/training/groundtruth/satImage_084.png\n",
      "Loading ../data/training/groundtruth/satImage_085.png\n",
      "Loading ../data/training/groundtruth/satImage_086.png\n",
      "Loading ../data/training/groundtruth/satImage_087.png\n",
      "Loading ../data/training/groundtruth/satImage_088.png\n",
      "Loading ../data/training/groundtruth/satImage_089.png\n",
      "Loading ../data/training/groundtruth/satImage_090.png\n",
      "Loading ../data/training/groundtruth/satImage_091.png\n",
      "Loading ../data/training/groundtruth/satImage_092.png\n",
      "Loading ../data/training/groundtruth/satImage_093.png\n",
      "Loading ../data/training/groundtruth/satImage_094.png\n",
      "Loading ../data/training/groundtruth/satImage_095.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data/training/groundtruth/satImage_096.png\n",
      "Loading ../data/training/groundtruth/satImage_097.png\n",
      "Loading ../data/training/groundtruth/satImage_098.png\n",
      "Loading ../data/training/groundtruth/satImage_099.png\n",
      "Loading ../data/training/groundtruth/satImage_100.png\n"
     ]
    }
   ],
   "source": [
    "def extract_data(filename, num_images):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "    Values are scaled from [0, 1] instead of [0,255].\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    \n",
    "    return np.asarray(imgs)\n",
    "\n",
    "train_raw = extract_data(train_data_filename, TRAINING_SIZE)\n",
    "ground_truth_raw = extract_data(train_labels_filename, TRAINING_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data/test_set_images/test_1/test_1.png\n",
      "Loading ../data/test_set_images/test_2/test_2.png\n",
      "Loading ../data/test_set_images/test_3/test_3.png\n",
      "Loading ../data/test_set_images/test_4/test_4.png\n",
      "Loading ../data/test_set_images/test_5/test_5.png\n",
      "Loading ../data/test_set_images/test_6/test_6.png\n",
      "Loading ../data/test_set_images/test_7/test_7.png\n",
      "Loading ../data/test_set_images/test_8/test_8.png\n",
      "Loading ../data/test_set_images/test_9/test_9.png\n",
      "Loading ../data/test_set_images/test_10/test_10.png\n",
      "Loading ../data/test_set_images/test_11/test_11.png\n",
      "Loading ../data/test_set_images/test_12/test_12.png\n",
      "Loading ../data/test_set_images/test_13/test_13.png\n",
      "Loading ../data/test_set_images/test_14/test_14.png\n",
      "Loading ../data/test_set_images/test_15/test_15.png\n",
      "Loading ../data/test_set_images/test_16/test_16.png\n",
      "Loading ../data/test_set_images/test_17/test_17.png\n",
      "Loading ../data/test_set_images/test_18/test_18.png\n",
      "Loading ../data/test_set_images/test_19/test_19.png\n",
      "Loading ../data/test_set_images/test_20/test_20.png\n",
      "Loading ../data/test_set_images/test_21/test_21.png\n",
      "Loading ../data/test_set_images/test_22/test_22.png\n",
      "Loading ../data/test_set_images/test_23/test_23.png\n",
      "Loading ../data/test_set_images/test_24/test_24.png\n",
      "Loading ../data/test_set_images/test_25/test_25.png\n",
      "Loading ../data/test_set_images/test_26/test_26.png\n",
      "Loading ../data/test_set_images/test_27/test_27.png\n",
      "Loading ../data/test_set_images/test_28/test_28.png\n",
      "Loading ../data/test_set_images/test_29/test_29.png\n",
      "Loading ../data/test_set_images/test_30/test_30.png\n",
      "Loading ../data/test_set_images/test_31/test_31.png\n",
      "Loading ../data/test_set_images/test_32/test_32.png\n",
      "Loading ../data/test_set_images/test_33/test_33.png\n",
      "Loading ../data/test_set_images/test_34/test_34.png\n",
      "Loading ../data/test_set_images/test_35/test_35.png\n",
      "Loading ../data/test_set_images/test_36/test_36.png\n",
      "Loading ../data/test_set_images/test_37/test_37.png\n",
      "Loading ../data/test_set_images/test_38/test_38.png\n",
      "Loading ../data/test_set_images/test_39/test_39.png\n",
      "Loading ../data/test_set_images/test_40/test_40.png\n",
      "Loading ../data/test_set_images/test_41/test_41.png\n",
      "Loading ../data/test_set_images/test_42/test_42.png\n",
      "Loading ../data/test_set_images/test_43/test_43.png\n",
      "Loading ../data/test_set_images/test_44/test_44.png\n",
      "Loading ../data/test_set_images/test_45/test_45.png\n",
      "Loading ../data/test_set_images/test_46/test_46.png\n",
      "Loading ../data/test_set_images/test_47/test_47.png\n",
      "Loading ../data/test_set_images/test_48/test_48.png\n",
      "Loading ../data/test_set_images/test_49/test_49.png\n",
      "Loading ../data/test_set_images/test_50/test_50.png\n"
     ]
    }
   ],
   "source": [
    "### Extract_test\n",
    "\n",
    "def extract_test(image_filename):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "    Values are scaled from [0, 1] instead of [0,255].\n",
    "    \"\"\"\n",
    "    if os.path.isfile(image_filename):\n",
    "        print ('Loading ' + image_filename)\n",
    "        return mpimg.imread(image_filename)\n",
    "    \n",
    "# Get filenames and images for all the 50 submission images\n",
    "image_dir = [root_dir + \"test_{}/\".format(i) for i in range(1, TEST_SIZE+1)]\n",
    "filenames = [fn for imdir in image_dir for fn in os.listdir(imdir)]\n",
    "images = np.asarray([extract_test(image_dir[i-1] + filenames[i-1]) for i in range(1, TEST_SIZE+1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(train, ground_truth=None, gt=True):\n",
    "    X_train = (train-0.5)/0.5\n",
    "    if gt:\n",
    "        Y_ground_truth = (ground_truth - ground_truth.min())/(ground_truth.max()-ground_truth.min())\n",
    "        return X_train, Y_ground_truth\n",
    "    else:\n",
    "        return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, ground_truth = process(train_raw, ground_truth_raw)\n",
    "#test_images = process(images, gt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(train, ground_truth):\n",
    "    imgs_processed=[]\n",
    "    labels_processed = []\n",
    "    \n",
    "    for i in range(len(train)):\n",
    "        \n",
    "        img = train[i]\n",
    "        img_gt = ground_truth[i]\n",
    "        \n",
    "        img_ud = np.flipud(img)\n",
    "        img_gt_ud = np.flipud(img_gt)\n",
    "\n",
    "        img_lr = np.fliplr(img)\n",
    "        img_gt_lr = np.fliplr(img_gt)\n",
    "\n",
    "        img_180 = np.rot90(img, 1)\n",
    "        img_gt_180 = np.rot90(img_gt, 1)\n",
    "\n",
    "        angle= np.random.randint(180)\n",
    "        img_angle1 = scipy.ndimage.interpolation.rotate(img, angle, mode='reflect', reshape=False, order=0)\n",
    "        img_gt_angle1 = scipy.ndimage.interpolation.rotate(img_gt, angle, mode='reflect', reshape=False, order=0)\n",
    "\n",
    "        angle= np.random.randint(180)\n",
    "        img_angle2 = scipy.ndimage.interpolation.rotate(img, angle, mode='reflect', reshape=False, order=0)\n",
    "        img_gt_angle2 = scipy.ndimage.interpolation.rotate(img_gt, angle, mode='reflect', reshape=False, order=0)\n",
    "\n",
    "        angle= np.random.randint(180)\n",
    "        img_angle3 = scipy.ndimage.interpolation.rotate(img, angle, mode='reflect', reshape=False, order=0)\n",
    "        img_gt_angle3 = scipy.ndimage.interpolation.rotate(img_gt, angle, mode='reflect', reshape=False, order=0)\n",
    "\n",
    "        \n",
    "        imgs_processed.extend([img, img_ud, img_lr, img_180, img_angle1, img_angle2, img_angle3])\n",
    "        labels_processed.extend([img_gt, img_gt_ud, img_gt_lr, img_gt_180, img_gt_angle1, img_gt_angle2, img_gt_angle3])\n",
    "    \n",
    "    return imgs_processed, labels_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train, augmented_ground_truth = data_augmentation(train, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding part and crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_crop_gt(im, w, h, stride):\n",
    "    \"\"\" Crop an image into patches (this method is intended for ground truth images). \"\"\"\n",
    "    assert len(im.shape) == 2, 'Expected greyscale image.'\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    for i in range(0,imgheight,stride):\n",
    "        for j in range(0,imgwidth,stride):\n",
    "            im_patch = im[j:j+w, i:i+h]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "    \n",
    "def img_crop(im, w, h, stride, padding):\n",
    "    \"\"\" Crop an image into patches, taking into account mirror boundary conditions. \"\"\"\n",
    "    assert len(im.shape) == 3, 'Expected RGB image.'\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    im = np.lib.pad(im, ((padding, padding), (padding, padding), (0,0)), 'reflect')\n",
    "    for i in range(padding,imgheight+padding,stride):\n",
    "        for j in range(padding,imgwidth+padding,stride):\n",
    "            im_patch = im[j-padding:j+w+padding, i-padding:i+h+padding, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_padding(train, ground_truth, patch_size, stride, window_size):\n",
    "    padding = (window_size - patch_size)//2\n",
    "    \n",
    "    crop_and_padding_train = []\n",
    "    crop_and_padding_ground_truth = []\n",
    "    \n",
    "    for i in range(len(train)):\n",
    "        cp_train = img_crop(train[i], patch_size, patch_size, stride, padding)\n",
    "        cp_gt = img_crop_gt(ground_truth[i], patch_size, patch_size, stride)\n",
    "        \n",
    "        crop_and_padding_train.extend(cp_train)\n",
    "        crop_and_padding_ground_truth.extend(cp_gt)\n",
    "    \n",
    "    return crop_and_padding_train, crop_and_padding_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data, train_gt = crop_and_padding(augmented_train, augmented_ground_truth, 16, 16, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create balanced sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def balanced_data(train_data, train_gt, threshold=0.25):\n",
    "    \n",
    "    labels = np.array([(np.mean(train_gt[i]) > threshold)*1 for i in range(len(train_gt))])\n",
    "    idx0 = [i for i,v in enumerate(labels) if v==0]\n",
    "    idx1 = [i for i,v in enumerate(labels) if v==1]\n",
    "    min_c = min(len(idx0),len(idx1))\n",
    "    print(2*min_c)\n",
    "    new_indices = idx0[0:min_c] + idx1[0:min_c]\n",
    "    train_data = [train_data[i] for i in new_indices]\n",
    "    train_gt = [train_gt[i] for i in new_indices]\n",
    "    labels = [(np.mean(train_gt[i]) > threshold)*1 for i in range(len(train_gt))]\n",
    "    return train_data, train_gt, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t,_, labels = balanced_data(train_data, train_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(layer, filters_size, kernel_size, s, padding, activation='relu'):\n",
    "    if activation=='relu':\n",
    "        activation=tf.nn.relu\n",
    "    return tf.layers.conv2d(layer, filters=filters_size,  kernel_size=[kernel_size, kernel_size], strides=[s, s], padding=padding, activation=activation)\n",
    "\n",
    "def pooling(layer, k=2, s=2, pool_type='max'):\n",
    "    \n",
    "    if pool_type=='max':\n",
    "        return tf.layers.max_pooling2d(layer, pool_size=[k,k], strides=s)\n",
    "    \n",
    "def dense(layer, inputs_size, outputs_size, he_std=0.1):\n",
    "    weights = tf.Variable(tf.truncated_normal([inputs_size, outputs_size],stddev=he_std))\n",
    "    biases = tf.Variable(tf.constant(he_std, shape=[outputs_size]))\n",
    "    layer = tf.matmul(layer,weights) + biases  \n",
    "    return layer\n",
    "\n",
    "def flattening_layer(layer):\n",
    "        #make it single dimensional\n",
    "        input_size = layer.get_shape().as_list()\n",
    "        new_size = input_size[-1] * input_size[-2] * input_size[-3]\n",
    "        return tf.reshape(layer, [-1, new_size]),new_size\n",
    "    \n",
    "\n",
    "def activation(layer, activation='no_activation'):\n",
    "    if activation=='relu':\n",
    "        return tf.nn.relu(layer)\n",
    "    elif activation=='soft_max':\n",
    "        return tf.nn.softmax(layer)\n",
    "    elif activation=='sigmoid':\n",
    "        return tf.nn.sigmoid(layer)\n",
    "    else:\n",
    "        return layer\n",
    "    \n",
    "def optimizer_choice(name='GD', lr=0.003):\n",
    "    if name=='GD':\n",
    "        return tf.train.GradientDescentOptimizer(lr)\n",
    "    elif name=='adam':\n",
    "        return tf.train.AdamOptimizer(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "\n",
    "# Change in prepare_batch the 480 by n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, window_size=72, patch_size=16, stride=16, p=0.25):\n",
    "        print('init done')\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.p = 0.25\n",
    "        self.network = None\n",
    "        self.training_op = None\n",
    "        self.out = None\n",
    "        self.session = None\n",
    "        self.stride = stride\n",
    "        self.window_size=window_size\n",
    "        self.patch_size=patch_size\n",
    "        self.padding=(self.window_size-self.patch_size)//2\n",
    "        self.accuracy = None\n",
    "        self.loss = None\n",
    "    \n",
    "        \n",
    "        \n",
    "    def model(self):\n",
    "        # init the graph \n",
    "        #graph = tf.Graph()\n",
    "        #graph.seed = 1\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        #with graph.as_default():\n",
    "\n",
    "        # init the placeholder (None is given for more flexibility in batch_size)\n",
    "        # 16,16 will be put as parameters in a further version\n",
    "        self.X = tf.placeholder(\n",
    "                tf.float32,\n",
    "                shape=[None, self.window_size, self.window_size, 3], name='X')\n",
    "\n",
    "        self.y = tf.placeholder(tf.float32, shape=[None, 1], name='y')\n",
    "        self.p = tf.placeholder(tf.float32, name='p')\n",
    "\n",
    "         # Initialize first convolution step \n",
    "        self.network = conv2d(self.X, 64, 5, 1, 'SAME', tf.nn.relu)\n",
    "        self.network = pooling(self.network)\n",
    "        self.network = tf.nn.dropout(self.network, self.p)\n",
    "\n",
    "        self.network = conv2d(self.network, 128, 3, 1, 'SAME', tf.nn.relu)\n",
    "        self.network = pooling(self.network)\n",
    "        self.network = tf.nn.dropout(self.network, self.p)\n",
    "\n",
    "        self.network = conv2d(self.network, 256, 3, 1, 'SAME', tf.nn.relu)\n",
    "        self.network = pooling(self.network)\n",
    "        self.network = tf.nn.dropout(self.network, self.p)\n",
    "\n",
    "        self.network = conv2d(self.network, 256, 3, 1, 'SAME', tf.nn.relu)\n",
    "        self.network = pooling(self.network)\n",
    "        self.network = tf.nn.dropout(self.network, self.p)\n",
    "\n",
    "\n",
    "        # flatten last convolution step for full connected NN\n",
    "        self.network, flatten_size = flattening_layer(self.network)\n",
    "\n",
    "        # Initialize first full connected step\n",
    "        self.network = dense(self.network, \n",
    "                     flatten_size, \n",
    "                     1)\n",
    "        #self.network = tf.nn.dropout(self.network, self.p*2, name='out')\n",
    "        self.network = tf.nn.dropout(self.network, self.p)\n",
    "\n",
    "        self.out = self.network\n",
    "        self.out = tf.identity(self.out, name='out')\n",
    "        \n",
    "        cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=self.y, logits=self.out)\n",
    "        self.loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "\n",
    "\n",
    "        ## Initialize the choosen Optimizer\n",
    "        optimizer = optimizer_choice('adam', 0.001)\n",
    "        self.training_op = optimizer.minimize(self.loss, name='training_op')\n",
    "\n",
    "\n",
    "        # Initialize all Variables\n",
    "        #init = tf.global_variables_initializer()\n",
    "\n",
    "        predicted = tf.nn.sigmoid(self.out)\n",
    "        correct_pred = tf.equal(tf.round(predicted), self.y)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    " \n",
    "    def prepare_batches(self, seq, step):\n",
    "        n = len(seq)\n",
    "        print(n)\n",
    "        res = []\n",
    "        for i in range(0, n, step):\n",
    "            res.append(seq[i:i+step])\n",
    "        return res\n",
    "    \n",
    "    \n",
    "    def train(self, train, ground_truth, batchsize=120, number_epochs=1, saver_filename=None, to_save=True):\n",
    "        assert saver_filename != None\n",
    "        cost_history = np.empty(shape=[1],dtype=float)\n",
    "                \n",
    "        train1, ground_truth1 = crop_and_padding(train, ground_truth, self.patch_size, self.stride, self.window_size)\n",
    "        # Balanced data to improve performance\n",
    "        train_data, gt, labels = balanced_data(train1, ground_truth1)\n",
    "        \n",
    "        print(train_data[0].min(), train_data[2].max(), train_data[0].mean())\n",
    "        print(np.array(labels).mean())\n",
    "        \n",
    "        #np.random.seed(999)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            self.session = sess\n",
    "            self.session.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "            for iepoch in range(number_epochs):\n",
    "                \n",
    "                print(iepoch)\n",
    "                train_idx_shuffle = np.arange(len(train_data))\n",
    "                np.random.shuffle(train_idx_shuffle)\n",
    "                print(train_idx_shuffle)\n",
    "                batches = self.prepare_batches(train_idx_shuffle, batchsize)        \n",
    "\n",
    "                for nb, idx in enumerate(batches):\n",
    "                        \n",
    "\n",
    "                    #gt_batch = np.array(gt)[idx]\n",
    "                    #X_batch = tf.convert_to_tensor([train_data[j] for j in idx], dtype=tf.float32)\n",
    "                    #Y_batch = tf.convert_to_tensor([labels[j] for j in idx], dtype=tf.float32)#np.array(labels)[idx].reshape(-1,1)\n",
    "                    \n",
    "                    gt_batch = [gt[j] for j in idx]\n",
    "                    X_batch = [train_data[j] for j in idx]\n",
    "                    Y_batch = np.array([labels[j] for j in idx]).reshape(-1,1)\n",
    "\n",
    "                    feed_dict = {\n",
    "                            self.X: X_batch,\n",
    "                            self.y: Y_batch,\n",
    "                            self.p: 0.25\n",
    "                           }\n",
    "                    self.session.run(self.training_op, feed_dict=feed_dict)\n",
    "                    cost, _, acc = self.session.run([self.loss, self.training_op, self.accuracy], feed_dict={\n",
    "                                         self.X: X_batch, self.y: Y_batch, self.p: 1})\n",
    "                    cost_history = np.append(cost_history, acc)\n",
    "\n",
    "                    if nb % 100 == 0:\n",
    "                        print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(\n",
    "                            nb, cost, acc))\n",
    "            if to_save:\n",
    "                saver = tf.train.Saver() \n",
    "                saver.save(self.session, '../models/' + saver_filename + '.ckpt')\n",
    "            \n",
    "            return X_batch, Y_batch, gt_batch\n",
    "            \n",
    "    def predict(self, images, to_submit=False, to_submit_filename=None, restore=False, saver_filename=None):\n",
    "        \n",
    "        if restore:\n",
    "            sess = tf.Session()\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess, '../models/' + saver_filename + '.ckpt')\n",
    "        else:\n",
    "            print('Restoring is needed to predict.')\n",
    "            \n",
    "        if to_submit:\n",
    "            with open(to_submit_filename, 'w') as f:\n",
    "                f.write('id,prediction\\n')\n",
    "                for test in range(1, TEST_SIZE+1,1):\n",
    "                    print(test)\n",
    "                    f.writelines('{}\\n'.format(s) for s in self.submission_per_patch(sess, images, test))\n",
    "        else:\n",
    "            test_patches = np.array(img_crop(images, self.patch_size, self.patch_size, self.stride, self.padding))\n",
    "            Z = sess.run(self.out, feed_dict={self.X: test_patches, self.p: 1})\n",
    "            prediction = Z.reshape(-1)\n",
    "            prediction = np.array([sigmoid(i) for i in prediction])\n",
    "            prediction = (prediction > 0.5) *1\n",
    "            \n",
    "            return Z, prediction\n",
    "        \n",
    "            \n",
    "    def submission_per_patch(self, session, images, img_number):    \n",
    "\n",
    "        test_patches = np.array(img_crop(images[img_number-1], self.patch_size, self.patch_size, self.stride, self.padding))\n",
    "        Z = session.run(self.out, feed_dict={self.X: test_patches, self.p: 1})\n",
    "        prediction = Z.reshape(-1)\n",
    "        prediction = np.array([sigmoid(i) for i in prediction])\n",
    "        prediction = (prediction > 0.5) *1\n",
    "        if img_number == 2:\n",
    "            print(prediction)\n",
    "            print(int(prediction[8]))\n",
    "        patch_size = 16\n",
    "        nb = 0\n",
    "        print(\"Processing \" + str(img_number-1))\n",
    "        for j in range(0, images[img_number-1].shape[1], patch_size):\n",
    "            for i in range(0, images[img_number-1].shape[0], patch_size):\n",
    "                label = int(prediction[nb])\n",
    "                nb += 1\n",
    "                yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init done\n"
     ]
    }
   ],
   "source": [
    "cnn_TEST = CNN(window_size=62)\n",
    "cnn_TEST.model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change number_epochs to 20 and saver_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227776\n",
      "-1.0 0.64705884 -0.6153779\n",
      "0.5\n",
      "0\n",
      "[105005 175619 195220 ...    393 109352  51053]\n",
      "227776\n",
      "Step:     0\tLoss: 0.733\tAcc: 55.00%\n",
      "Step:   100\tLoss: 0.685\tAcc: 59.17%\n",
      "Step:   200\tLoss: 0.680\tAcc: 57.50%\n",
      "Step:   300\tLoss: 0.694\tAcc: 60.00%\n",
      "Step:   400\tLoss: 0.644\tAcc: 62.50%\n",
      "Step:   500\tLoss: 0.700\tAcc: 55.00%\n",
      "Step:   600\tLoss: 0.572\tAcc: 75.00%\n",
      "Step:   700\tLoss: 0.604\tAcc: 67.50%\n",
      "Step:   800\tLoss: 0.611\tAcc: 65.00%\n",
      "Step:   900\tLoss: 0.435\tAcc: 77.50%\n",
      "Step:  1000\tLoss: 0.493\tAcc: 81.67%\n",
      "Step:  1100\tLoss: 0.456\tAcc: 81.67%\n",
      "Step:  1200\tLoss: 0.389\tAcc: 85.83%\n",
      "Step:  1300\tLoss: 0.414\tAcc: 81.67%\n",
      "Step:  1400\tLoss: 0.436\tAcc: 80.00%\n",
      "Step:  1500\tLoss: 0.413\tAcc: 85.00%\n",
      "Step:  1600\tLoss: 0.461\tAcc: 76.67%\n",
      "Step:  1700\tLoss: 0.321\tAcc: 87.50%\n",
      "Step:  1800\tLoss: 0.388\tAcc: 78.33%\n",
      "1\n",
      "[ 38793  24677 211748 ... 147014   3974 195939]\n",
      "227776\n",
      "Step:     0\tLoss: 0.472\tAcc: 73.33%\n",
      "Step:   100\tLoss: 0.415\tAcc: 82.50%\n",
      "Step:   200\tLoss: 0.404\tAcc: 86.67%\n",
      "Step:   300\tLoss: 0.349\tAcc: 86.67%\n",
      "Step:   400\tLoss: 0.461\tAcc: 75.83%\n",
      "Step:   500\tLoss: 0.393\tAcc: 82.50%\n",
      "Step:   600\tLoss: 0.293\tAcc: 87.50%\n",
      "Step:   700\tLoss: 0.269\tAcc: 90.83%\n",
      "Step:   800\tLoss: 0.320\tAcc: 87.50%\n",
      "Step:   900\tLoss: 0.368\tAcc: 84.17%\n",
      "Step:  1000\tLoss: 0.347\tAcc: 85.83%\n",
      "Step:  1100\tLoss: 0.299\tAcc: 83.33%\n",
      "Step:  1200\tLoss: 0.387\tAcc: 80.00%\n",
      "Step:  1300\tLoss: 0.336\tAcc: 85.83%\n",
      "Step:  1400\tLoss: 0.300\tAcc: 89.17%\n",
      "Step:  1500\tLoss: 0.274\tAcc: 88.33%\n",
      "Step:  1600\tLoss: 0.343\tAcc: 85.00%\n",
      "Step:  1700\tLoss: 0.332\tAcc: 87.50%\n",
      "Step:  1800\tLoss: 0.352\tAcc: 83.33%\n",
      "2\n",
      "[ 26510 163303 186102 ... 142058 133444  58032]\n",
      "227776\n",
      "Step:     0\tLoss: 0.287\tAcc: 89.17%\n",
      "Step:   100\tLoss: 0.265\tAcc: 93.33%\n",
      "Step:   200\tLoss: 0.291\tAcc: 85.83%\n",
      "Step:   300\tLoss: 0.253\tAcc: 87.50%\n",
      "Step:   400\tLoss: 0.267\tAcc: 90.00%\n",
      "Step:   500\tLoss: 0.211\tAcc: 93.33%\n",
      "Step:   600\tLoss: 0.244\tAcc: 91.67%\n",
      "Step:   700\tLoss: 0.356\tAcc: 84.17%\n",
      "Step:   800\tLoss: 0.320\tAcc: 85.83%\n",
      "Step:   900\tLoss: 0.295\tAcc: 86.67%\n",
      "Step:  1000\tLoss: 0.288\tAcc: 90.00%\n",
      "Step:  1100\tLoss: 0.301\tAcc: 88.33%\n",
      "Step:  1200\tLoss: 0.231\tAcc: 90.83%\n",
      "Step:  1300\tLoss: 0.281\tAcc: 85.83%\n",
      "Step:  1400\tLoss: 0.165\tAcc: 94.17%\n",
      "Step:  1500\tLoss: 0.185\tAcc: 91.67%\n",
      "Step:  1600\tLoss: 0.224\tAcc: 88.33%\n",
      "Step:  1700\tLoss: 0.287\tAcc: 89.17%\n",
      "Step:  1800\tLoss: 0.213\tAcc: 90.00%\n",
      "3\n",
      "[212712 170643  50127 ...   5423  10291  82238]\n",
      "227776\n",
      "Step:     0\tLoss: 0.245\tAcc: 91.67%\n",
      "Step:   100\tLoss: 0.248\tAcc: 90.00%\n",
      "Step:   200\tLoss: 0.244\tAcc: 90.83%\n",
      "Step:   300\tLoss: 0.272\tAcc: 88.33%\n",
      "Step:   400\tLoss: 0.230\tAcc: 90.83%\n",
      "Step:   500\tLoss: 0.157\tAcc: 95.00%\n",
      "Step:   600\tLoss: 0.265\tAcc: 87.50%\n",
      "Step:   700\tLoss: 0.165\tAcc: 94.17%\n",
      "Step:   800\tLoss: 0.284\tAcc: 87.50%\n",
      "Step:   900\tLoss: 0.236\tAcc: 89.17%\n",
      "Step:  1000\tLoss: 0.194\tAcc: 92.50%\n",
      "Step:  1100\tLoss: 0.278\tAcc: 85.83%\n",
      "Step:  1200\tLoss: 0.218\tAcc: 92.50%\n",
      "Step:  1300\tLoss: 0.413\tAcc: 87.50%\n",
      "Step:  1400\tLoss: 0.200\tAcc: 90.83%\n",
      "Step:  1500\tLoss: 0.246\tAcc: 92.50%\n",
      "Step:  1600\tLoss: 0.230\tAcc: 91.67%\n",
      "Step:  1700\tLoss: 0.176\tAcc: 91.67%\n",
      "Step:  1800\tLoss: 0.123\tAcc: 93.33%\n",
      "4\n",
      "[ 59723 170121 105577 ... 111847  85514  21671]\n",
      "227776\n",
      "Step:     0\tLoss: 0.265\tAcc: 88.33%\n",
      "Step:   100\tLoss: 0.181\tAcc: 92.50%\n",
      "Step:   200\tLoss: 0.291\tAcc: 86.67%\n",
      "Step:   300\tLoss: 0.202\tAcc: 91.67%\n",
      "Step:   400\tLoss: 0.177\tAcc: 90.00%\n",
      "Step:   500\tLoss: 0.204\tAcc: 91.67%\n",
      "Step:   600\tLoss: 0.182\tAcc: 91.67%\n",
      "Step:   700\tLoss: 0.207\tAcc: 93.33%\n",
      "Step:   800\tLoss: 0.198\tAcc: 92.50%\n",
      "Step:   900\tLoss: 0.212\tAcc: 91.67%\n",
      "Step:  1000\tLoss: 0.259\tAcc: 92.50%\n",
      "Step:  1100\tLoss: 0.248\tAcc: 85.83%\n",
      "Step:  1200\tLoss: 0.132\tAcc: 94.17%\n",
      "Step:  1300\tLoss: 0.121\tAcc: 95.00%\n",
      "Step:  1400\tLoss: 0.192\tAcc: 91.67%\n",
      "Step:  1500\tLoss: 0.190\tAcc: 93.33%\n",
      "Step:  1600\tLoss: 0.223\tAcc: 90.00%\n",
      "Step:  1700\tLoss: 0.203\tAcc: 90.83%\n",
      "Step:  1800\tLoss: 0.229\tAcc: 90.83%\n",
      "5\n",
      "[136552 162111  14750 ...  90698  93083  36160]\n",
      "227776\n",
      "Step:     0\tLoss: 0.200\tAcc: 91.67%\n",
      "Step:   100\tLoss: 0.153\tAcc: 93.33%\n",
      "Step:   200\tLoss: 0.139\tAcc: 94.17%\n",
      "Step:   300\tLoss: 0.169\tAcc: 95.00%\n",
      "Step:   400\tLoss: 0.175\tAcc: 91.67%\n",
      "Step:   500\tLoss: 0.277\tAcc: 88.33%\n",
      "Step:   600\tLoss: 0.115\tAcc: 94.17%\n",
      "Step:   700\tLoss: 0.163\tAcc: 92.50%\n",
      "Step:   800\tLoss: 0.122\tAcc: 94.17%\n",
      "Step:   900\tLoss: 0.152\tAcc: 95.00%\n",
      "Step:  1000\tLoss: 0.202\tAcc: 90.83%\n",
      "Step:  1100\tLoss: 0.164\tAcc: 95.83%\n",
      "Step:  1200\tLoss: 0.151\tAcc: 94.17%\n",
      "Step:  1300\tLoss: 0.157\tAcc: 95.83%\n",
      "Step:  1400\tLoss: 0.205\tAcc: 93.33%\n",
      "Step:  1500\tLoss: 0.193\tAcc: 90.00%\n",
      "Step:  1600\tLoss: 0.233\tAcc: 90.83%\n",
      "Step:  1700\tLoss: 0.148\tAcc: 94.17%\n",
      "Step:  1800\tLoss: 0.249\tAcc: 92.50%\n",
      "6\n",
      "[139734   2257 100635 ...  87400 145555 108138]\n",
      "227776\n",
      "Step:     0\tLoss: 0.120\tAcc: 93.33%\n",
      "Step:   100\tLoss: 0.097\tAcc: 96.67%\n",
      "Step:   200\tLoss: 0.147\tAcc: 93.33%\n",
      "Step:   300\tLoss: 0.093\tAcc: 95.83%\n",
      "Step:   400\tLoss: 0.189\tAcc: 93.33%\n",
      "Step:   500\tLoss: 0.205\tAcc: 87.50%\n",
      "Step:   600\tLoss: 0.224\tAcc: 90.83%\n",
      "Step:   700\tLoss: 0.176\tAcc: 90.83%\n",
      "Step:   800\tLoss: 0.141\tAcc: 91.67%\n",
      "Step:   900\tLoss: 0.193\tAcc: 91.67%\n",
      "Step:  1000\tLoss: 0.099\tAcc: 94.17%\n",
      "Step:  1100\tLoss: 0.234\tAcc: 90.00%\n",
      "Step:  1200\tLoss: 0.205\tAcc: 89.17%\n",
      "Step:  1300\tLoss: 0.147\tAcc: 93.33%\n",
      "Step:  1400\tLoss: 0.136\tAcc: 92.50%\n",
      "Step:  1500\tLoss: 0.269\tAcc: 89.17%\n",
      "Step:  1600\tLoss: 0.144\tAcc: 95.83%\n",
      "Step:  1700\tLoss: 0.176\tAcc: 91.67%\n",
      "Step:  1800\tLoss: 0.200\tAcc: 92.50%\n",
      "7\n",
      "[150124  80908 158127 ...   3024 154948 168110]\n",
      "227776\n",
      "Step:     0\tLoss: 0.185\tAcc: 89.17%\n",
      "Step:   100\tLoss: 0.117\tAcc: 94.17%\n",
      "Step:   200\tLoss: 0.204\tAcc: 90.00%\n",
      "Step:   300\tLoss: 0.135\tAcc: 92.50%\n",
      "Step:   400\tLoss: 0.156\tAcc: 92.50%\n",
      "Step:   500\tLoss: 0.079\tAcc: 97.50%\n",
      "Step:   600\tLoss: 0.119\tAcc: 96.67%\n",
      "Step:   700\tLoss: 0.134\tAcc: 94.17%\n",
      "Step:   800\tLoss: 0.124\tAcc: 95.00%\n",
      "Step:   900\tLoss: 0.088\tAcc: 95.83%\n",
      "Step:  1000\tLoss: 0.147\tAcc: 94.17%\n",
      "Step:  1100\tLoss: 0.195\tAcc: 90.00%\n",
      "Step:  1200\tLoss: 0.189\tAcc: 90.00%\n",
      "Step:  1300\tLoss: 0.094\tAcc: 98.33%\n",
      "Step:  1400\tLoss: 0.052\tAcc: 98.33%\n",
      "Step:  1500\tLoss: 0.139\tAcc: 97.50%\n",
      "Step:  1600\tLoss: 0.119\tAcc: 95.83%\n",
      "Step:  1700\tLoss: 0.222\tAcc: 90.00%\n",
      "Step:  1800\tLoss: 0.140\tAcc: 94.17%\n",
      "8\n",
      "[140226 221643   5387 ... 173326 220157  23547]\n",
      "227776\n",
      "Step:     0\tLoss: 0.277\tAcc: 90.00%\n",
      "Step:   100\tLoss: 0.249\tAcc: 92.50%\n",
      "Step:   200\tLoss: 0.248\tAcc: 90.83%\n",
      "Step:   300\tLoss: 0.074\tAcc: 95.83%\n",
      "Step:   400\tLoss: 0.231\tAcc: 92.50%\n",
      "Step:   500\tLoss: 0.176\tAcc: 91.67%\n",
      "Step:   600\tLoss: 0.143\tAcc: 94.17%\n",
      "Step:   700\tLoss: 0.214\tAcc: 93.33%\n",
      "Step:   800\tLoss: 0.071\tAcc: 95.83%\n",
      "Step:   900\tLoss: 0.200\tAcc: 91.67%\n",
      "Step:  1000\tLoss: 0.169\tAcc: 94.17%\n",
      "Step:  1100\tLoss: 0.291\tAcc: 89.17%\n",
      "Step:  1200\tLoss: 0.109\tAcc: 97.50%\n",
      "Step:  1300\tLoss: 0.126\tAcc: 94.17%\n",
      "Step:  1400\tLoss: 0.098\tAcc: 97.50%\n",
      "Step:  1500\tLoss: 0.122\tAcc: 95.00%\n",
      "Step:  1600\tLoss: 0.110\tAcc: 95.00%\n",
      "Step:  1700\tLoss: 0.115\tAcc: 95.83%\n",
      "Step:  1800\tLoss: 0.112\tAcc: 95.00%\n",
      "9\n",
      "[189158 139767  83038 ... 224837  53068 106098]\n",
      "227776\n",
      "Step:     0\tLoss: 0.099\tAcc: 95.83%\n",
      "Step:   100\tLoss: 0.065\tAcc: 97.50%\n",
      "Step:   200\tLoss: 0.086\tAcc: 95.83%\n",
      "Step:   300\tLoss: 0.084\tAcc: 98.33%\n",
      "Step:   400\tLoss: 0.105\tAcc: 92.50%\n",
      "Step:   500\tLoss: 0.143\tAcc: 94.17%\n",
      "Step:   600\tLoss: 0.105\tAcc: 93.33%\n",
      "Step:   700\tLoss: 0.038\tAcc: 98.33%\n",
      "Step:   800\tLoss: 0.191\tAcc: 92.50%\n",
      "Step:   900\tLoss: 0.090\tAcc: 96.67%\n",
      "Step:  1000\tLoss: 0.118\tAcc: 96.67%\n",
      "Step:  1100\tLoss: 0.119\tAcc: 97.50%\n",
      "Step:  1200\tLoss: 0.214\tAcc: 90.00%\n",
      "Step:  1300\tLoss: 0.167\tAcc: 94.17%\n",
      "Step:  1400\tLoss: 0.103\tAcc: 95.00%\n",
      "Step:  1500\tLoss: 0.067\tAcc: 96.67%\n",
      "Step:  1600\tLoss: 0.069\tAcc: 98.33%\n",
      "Step:  1700\tLoss: 0.104\tAcc: 97.50%\n",
      "Step:  1800\tLoss: 0.074\tAcc: 96.67%\n"
     ]
    }
   ],
   "source": [
    "x_TEST, y_TEST, gt_TEST = cnn_TEST.train(augmented_train, augmented_ground_truth, saver_filename='model_10_epochs_72_window_size', number_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227776\n",
      "-1.0 0.64705884 -0.6089477\n",
      "0.5\n",
      "0\n",
      "[199471  73984  99619 ... 128754 180765 119397]\n",
      "227776\n",
      "Step:     0\tLoss: 0.693\tAcc: 51.67%\n",
      "Step:   100\tLoss: 0.690\tAcc: 55.00%\n",
      "Step:   200\tLoss: 0.685\tAcc: 60.83%\n",
      "Step:   300\tLoss: 0.689\tAcc: 56.67%\n",
      "Step:   400\tLoss: 0.693\tAcc: 50.00%\n",
      "Step:   500\tLoss: 0.656\tAcc: 59.17%\n",
      "Step:   600\tLoss: 0.691\tAcc: 47.50%\n",
      "Step:   700\tLoss: 0.651\tAcc: 56.67%\n",
      "Step:   800\tLoss: 0.651\tAcc: 66.67%\n",
      "Step:   900\tLoss: 0.634\tAcc: 69.17%\n",
      "Step:  1000\tLoss: 0.556\tAcc: 75.00%\n",
      "Step:  1100\tLoss: 0.487\tAcc: 79.17%\n",
      "Step:  1200\tLoss: 0.499\tAcc: 75.83%\n",
      "Step:  1300\tLoss: 0.450\tAcc: 80.83%\n",
      "Step:  1400\tLoss: 0.487\tAcc: 76.67%\n",
      "Step:  1500\tLoss: 0.369\tAcc: 85.00%\n",
      "Step:  1600\tLoss: 0.387\tAcc: 86.67%\n",
      "Step:  1700\tLoss: 0.360\tAcc: 86.67%\n",
      "Step:  1800\tLoss: 0.379\tAcc: 79.17%\n",
      "1\n",
      "[177427  92573  17889 ... 204433 182456 192934]\n",
      "227776\n",
      "Step:     0\tLoss: 0.412\tAcc: 82.50%\n",
      "Step:   100\tLoss: 0.397\tAcc: 81.67%\n",
      "Step:   200\tLoss: 0.322\tAcc: 85.00%\n",
      "Step:   300\tLoss: 0.349\tAcc: 84.17%\n",
      "Step:   400\tLoss: 0.277\tAcc: 86.67%\n",
      "Step:   500\tLoss: 0.289\tAcc: 86.67%\n",
      "Step:   600\tLoss: 0.297\tAcc: 86.67%\n",
      "Step:   700\tLoss: 0.421\tAcc: 78.33%\n",
      "Step:   800\tLoss: 0.373\tAcc: 85.83%\n",
      "Step:   900\tLoss: 0.275\tAcc: 86.67%\n",
      "Step:  1000\tLoss: 0.305\tAcc: 89.17%\n",
      "Step:  1100\tLoss: 0.375\tAcc: 80.83%\n",
      "Step:  1200\tLoss: 0.278\tAcc: 90.00%\n",
      "Step:  1300\tLoss: 0.313\tAcc: 85.83%\n",
      "Step:  1400\tLoss: 0.351\tAcc: 85.83%\n",
      "Step:  1500\tLoss: 0.334\tAcc: 80.00%\n",
      "Step:  1600\tLoss: 0.319\tAcc: 86.67%\n",
      "Step:  1700\tLoss: 0.328\tAcc: 85.00%\n",
      "Step:  1800\tLoss: 0.268\tAcc: 88.33%\n",
      "2\n",
      "[ 46947 132351 102492 ... 209352  89177  86323]\n",
      "227776\n",
      "Step:     0\tLoss: 0.392\tAcc: 82.50%\n",
      "Step:   100\tLoss: 0.282\tAcc: 83.33%\n",
      "Step:   200\tLoss: 0.298\tAcc: 85.00%\n",
      "Step:   300\tLoss: 0.349\tAcc: 81.67%\n",
      "Step:   400\tLoss: 0.217\tAcc: 90.00%\n",
      "Step:   500\tLoss: 0.302\tAcc: 82.50%\n",
      "Step:   600\tLoss: 0.240\tAcc: 90.83%\n",
      "Step:   700\tLoss: 0.224\tAcc: 91.67%\n",
      "Step:   800\tLoss: 0.296\tAcc: 87.50%\n",
      "Step:   900\tLoss: 0.306\tAcc: 88.33%\n",
      "Step:  1000\tLoss: 0.202\tAcc: 92.50%\n",
      "Step:  1100\tLoss: 0.145\tAcc: 95.83%\n",
      "Step:  1200\tLoss: 0.218\tAcc: 90.00%\n",
      "Step:  1300\tLoss: 0.259\tAcc: 88.33%\n",
      "Step:  1400\tLoss: 0.231\tAcc: 89.17%\n",
      "Step:  1500\tLoss: 0.290\tAcc: 85.00%\n",
      "Step:  1600\tLoss: 0.338\tAcc: 89.17%\n",
      "Step:  1700\tLoss: 0.321\tAcc: 87.50%\n",
      "Step:  1800\tLoss: 0.259\tAcc: 88.33%\n",
      "3\n",
      "[177816   7218 225642 ... 135642 180813  64123]\n",
      "227776\n",
      "Step:     0\tLoss: 0.384\tAcc: 83.33%\n",
      "Step:   100\tLoss: 0.320\tAcc: 88.33%\n",
      "Step:   200\tLoss: 0.240\tAcc: 89.17%\n",
      "Step:   300\tLoss: 0.222\tAcc: 92.50%\n",
      "Step:   400\tLoss: 0.231\tAcc: 88.33%\n",
      "Step:   500\tLoss: 0.242\tAcc: 89.17%\n",
      "Step:   600\tLoss: 0.133\tAcc: 94.17%\n",
      "Step:   700\tLoss: 0.245\tAcc: 89.17%\n",
      "Step:   800\tLoss: 0.106\tAcc: 97.50%\n",
      "Step:   900\tLoss: 0.215\tAcc: 93.33%\n",
      "Step:  1000\tLoss: 0.211\tAcc: 93.33%\n",
      "Step:  1100\tLoss: 0.241\tAcc: 90.83%\n",
      "Step:  1200\tLoss: 0.255\tAcc: 89.17%\n",
      "Step:  1300\tLoss: 0.160\tAcc: 94.17%\n",
      "Step:  1400\tLoss: 0.258\tAcc: 88.33%\n",
      "Step:  1500\tLoss: 0.287\tAcc: 86.67%\n",
      "Step:  1600\tLoss: 0.162\tAcc: 94.17%\n",
      "Step:  1700\tLoss: 0.207\tAcc: 90.00%\n",
      "Step:  1800\tLoss: 0.221\tAcc: 90.00%\n",
      "4\n",
      "[114146 194326   2888 ...  47832  81867  45924]\n",
      "227776\n",
      "Step:     0\tLoss: 0.192\tAcc: 90.00%\n",
      "Step:   100\tLoss: 0.183\tAcc: 93.33%\n",
      "Step:   200\tLoss: 0.159\tAcc: 94.17%\n",
      "Step:   300\tLoss: 0.098\tAcc: 96.67%\n",
      "Step:   400\tLoss: 0.163\tAcc: 92.50%\n",
      "Step:   500\tLoss: 0.153\tAcc: 93.33%\n",
      "Step:   600\tLoss: 0.200\tAcc: 88.33%\n",
      "Step:   700\tLoss: 0.165\tAcc: 91.67%\n",
      "Step:   800\tLoss: 0.144\tAcc: 96.67%\n",
      "Step:   900\tLoss: 0.105\tAcc: 95.00%\n",
      "Step:  1000\tLoss: 0.151\tAcc: 92.50%\n",
      "Step:  1100\tLoss: 0.215\tAcc: 90.83%\n",
      "Step:  1200\tLoss: 0.183\tAcc: 95.83%\n",
      "Step:  1300\tLoss: 0.180\tAcc: 91.67%\n",
      "Step:  1400\tLoss: 0.152\tAcc: 92.50%\n",
      "Step:  1500\tLoss: 0.135\tAcc: 94.17%\n",
      "Step:  1600\tLoss: 0.174\tAcc: 95.00%\n",
      "Step:  1700\tLoss: 0.133\tAcc: 92.50%\n",
      "Step:  1800\tLoss: 0.168\tAcc: 93.33%\n",
      "5\n",
      "[ 68208  53128 153124 ... 183172 213324  43911]\n",
      "227776\n",
      "Step:     0\tLoss: 0.105\tAcc: 97.50%\n",
      "Step:   100\tLoss: 0.196\tAcc: 91.67%\n",
      "Step:   200\tLoss: 0.116\tAcc: 95.00%\n",
      "Step:   300\tLoss: 0.086\tAcc: 96.67%\n",
      "Step:   400\tLoss: 0.151\tAcc: 93.33%\n",
      "Step:   500\tLoss: 0.202\tAcc: 95.00%\n",
      "Step:   600\tLoss: 0.125\tAcc: 95.83%\n",
      "Step:   700\tLoss: 0.179\tAcc: 90.83%\n",
      "Step:   800\tLoss: 0.143\tAcc: 95.00%\n",
      "Step:   900\tLoss: 0.189\tAcc: 92.50%\n",
      "Step:  1000\tLoss: 0.077\tAcc: 98.33%\n",
      "Step:  1100\tLoss: 0.147\tAcc: 95.83%\n",
      "Step:  1200\tLoss: 0.129\tAcc: 95.00%\n",
      "Step:  1300\tLoss: 0.163\tAcc: 95.83%\n",
      "Step:  1400\tLoss: 0.199\tAcc: 95.00%\n",
      "Step:  1500\tLoss: 0.180\tAcc: 92.50%\n",
      "Step:  1600\tLoss: 0.104\tAcc: 96.67%\n",
      "Step:  1700\tLoss: 0.103\tAcc: 95.00%\n",
      "Step:  1800\tLoss: 0.115\tAcc: 95.83%\n",
      "6\n",
      "[200937 159391  88568 ... 190516  35408 131169]\n",
      "227776\n",
      "Step:     0\tLoss: 0.125\tAcc: 95.83%\n",
      "Step:   100\tLoss: 0.113\tAcc: 94.17%\n",
      "Step:   200\tLoss: 0.121\tAcc: 95.83%\n",
      "Step:   300\tLoss: 0.190\tAcc: 95.00%\n",
      "Step:   400\tLoss: 0.142\tAcc: 95.00%\n",
      "Step:   500\tLoss: 0.203\tAcc: 90.83%\n",
      "Step:   600\tLoss: 0.167\tAcc: 95.00%\n",
      "Step:   700\tLoss: 0.127\tAcc: 98.33%\n",
      "Step:   800\tLoss: 0.236\tAcc: 87.50%\n",
      "Step:   900\tLoss: 0.096\tAcc: 97.50%\n",
      "Step:  1000\tLoss: 0.111\tAcc: 96.67%\n",
      "Step:  1100\tLoss: 0.108\tAcc: 95.83%\n",
      "Step:  1200\tLoss: 0.208\tAcc: 90.83%\n",
      "Step:  1300\tLoss: 0.134\tAcc: 95.83%\n",
      "Step:  1400\tLoss: 0.166\tAcc: 90.00%\n",
      "Step:  1500\tLoss: 0.074\tAcc: 95.83%\n",
      "Step:  1600\tLoss: 0.104\tAcc: 95.00%\n",
      "Step:  1700\tLoss: 0.064\tAcc: 97.50%\n",
      "Step:  1800\tLoss: 0.085\tAcc: 98.33%\n",
      "7\n",
      "[136487 132931  23602 ... 161324 163945 177086]\n",
      "227776\n",
      "Step:     0\tLoss: 0.180\tAcc: 92.50%\n",
      "Step:   100\tLoss: 0.044\tAcc: 98.33%\n",
      "Step:   200\tLoss: 0.120\tAcc: 95.83%\n",
      "Step:   300\tLoss: 0.041\tAcc: 98.33%\n",
      "Step:   400\tLoss: 0.084\tAcc: 97.50%\n",
      "Step:   500\tLoss: 0.137\tAcc: 95.00%\n",
      "Step:   600\tLoss: 0.098\tAcc: 95.00%\n",
      "Step:   700\tLoss: 0.125\tAcc: 95.83%\n",
      "Step:   800\tLoss: 0.187\tAcc: 95.00%\n",
      "Step:   900\tLoss: 0.188\tAcc: 95.00%\n",
      "Step:  1000\tLoss: 0.081\tAcc: 95.00%\n",
      "Step:  1100\tLoss: 0.088\tAcc: 95.83%\n",
      "Step:  1200\tLoss: 0.224\tAcc: 93.33%\n",
      "Step:  1300\tLoss: 0.096\tAcc: 94.17%\n",
      "Step:  1400\tLoss: 0.051\tAcc: 99.17%\n",
      "Step:  1500\tLoss: 0.115\tAcc: 95.00%\n",
      "Step:  1600\tLoss: 0.064\tAcc: 97.50%\n",
      "Step:  1700\tLoss: 0.083\tAcc: 96.67%\n",
      "Step:  1800\tLoss: 0.122\tAcc: 93.33%\n",
      "8\n",
      "[ 70874 224444 181874 ...  71438  67616  53745]\n",
      "227776\n",
      "Step:     0\tLoss: 0.060\tAcc: 98.33%\n",
      "Step:   100\tLoss: 0.049\tAcc: 98.33%\n",
      "Step:   200\tLoss: 0.034\tAcc: 98.33%\n",
      "Step:   300\tLoss: 0.153\tAcc: 94.17%\n",
      "Step:   400\tLoss: 0.074\tAcc: 96.67%\n"
     ]
    }
   ],
   "source": [
    "x_TEST, y_TEST, gt_TEST = cnn_TEST.train(augmented_train, augmented_ground_truth, saver_filename='model_10_epochs_62_window_size', number_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_per_patch(session, graph, images, img_number, window_size, patch_size=16, stride=16):    \n",
    "    padding = (window_size-patch_size)//2\n",
    "    X = graph.get_tensor_by_name(\"X:0\")\n",
    "    y = graph.get_tensor_by_name(\"y:0\")\n",
    "    p = graph.get_tensor_by_name(\"p:0\")\n",
    "    #feed_dict ={X:X_train, p: 1}\n",
    "\n",
    "    #Now, access the op that you want to run. \n",
    "    op_to_restore = graph.get_tensor_by_name(\"out:0\")\n",
    "    \n",
    "    test_images = process(images, gt=False)\n",
    "    test_patches = np.array(img_crop(test_images[img_number-1], patch_size, patch_size, stride, padding))\n",
    "    if img_number==4:\n",
    "        print(test_patches.min(), test_patches.max())\n",
    "    \n",
    "    \n",
    "    Z = session.run(op_to_restore, feed_dict={X: test_patches, p: 1})\n",
    "    print(Z.mean())\n",
    "    prediction = Z.reshape(-1)\n",
    "    prediction = np.array([sigmoid(i) for i in prediction])\n",
    "    prediction = (prediction > 0.5) *1\n",
    "    print(prediction)\n",
    "    \n",
    "    patch_size = 16\n",
    "    nb = 0\n",
    "    print(\"Processing \" + str(img_number-1))\n",
    "    for j in range(0, images[img_number-1].shape[1], patch_size):\n",
    "        for i in range(0, images[img_number-1].shape[0], patch_size):\n",
    "            label = int(prediction[nb])\n",
    "            nb += 1\n",
    "            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/model_10_epochs_32_window_size.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()    \n",
    "#First let's load meta graph and restore weights\n",
    "saver = tf.train.import_meta_graph('../models/' + 'model_10_epochs_32_window_size' + '.ckpt.meta')\n",
    "saver.restore(sess, '../models/' + 'model_10_epochs_32_window_size' + '.ckpt')\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "X = graph.get_tensor_by_name(\"X:0\")\n",
    "y = graph.get_tensor_by_name(\"y:0\")\n",
    "p = graph.get_tensor_by_name(\"p:0\")\n",
    "#feed_dict ={X:X_train, p: 1}\n",
    "\n",
    "#Now, access the op that you want to run. \n",
    "op_to_restore = graph.get_tensor_by_name(\"out:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_54, train_gt_32 = crop_and_padding(augmented_train, augmented_ground_truth, 16, 16, 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_train = np.array(train_data_32[:20000])\n",
    "fold_test = np.array(train_gt_32[:20000])\n",
    "fold_labels = np.array([(fold_test[i].mean() > 0.25)*1 for i in range(fold_test.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sess.run(op_to_restore, feed_dict={X: train_data_32[:20000], p: 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fold = np.array([(sigmoid(Z[i])>0.5)*1 for i in range(fold_labels.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93105"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_fold == fold_labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaja\n"
     ]
    }
   ],
   "source": [
    "Z_id = sess.run(op_to_restore, feed_dict={X: fold_train, p: 1})\n",
    "Z_ud = sess.run(op_to_restore, feed_dict={X: flip_ud, p: 1})\n",
    "Z_lr = sess.run(op_to_restore, feed_dict={X: flip_lr, p: 1})\n",
    "print('jaja')\n",
    "Z_rot90 = sess.run(op_to_restore, feed_dict={X: flip_rot90, p: 1})\n",
    "Z_rot180 = sess.run(op_to_restore, feed_dict={X: flip_rot180, p: 1})\n",
    "Z_rot270 = sess.run(op_to_restore, feed_dict={X: flip_rot270, p: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fold = np.array([sigmoid(Z[i]) for i in range(fold_labels.shape[0])])\n",
    "pred_fold_ud = np.array([sigmoid(Z_ud[i]) for i in range(fold_labels.shape[0])])\n",
    "pred_fold_lr = np.array([sigmoid(Z_lr[i]) for i in range(fold_labels.shape[0])])\n",
    "pred_fold_rot90 = np.array([sigmoid(Z_rot90[i]) for i in range(fold_labels.shape[0])])\n",
    "pred_fold_rot180 = np.array([sigmoid(Z_rot180[i]) for i in range(fold_labels.shape[0])])\n",
    "pred_fold_rot270 = np.array([sigmoid(Z_rot270[i]) for i in range(fold_labels.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean = (pred_fold + pred_fold_ud + pred_fold_lr + pred_fold_rot90 + pred_fold_rot180 + pred_fold_rot270)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93295"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((pred_mean>0.55)*1 == fold_labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_ud = np.array([np.flipud(fold_train[i]) for i in range(fold_train.shape[0])])\n",
    "flip_lr = np.array([np.fliplr(fold_train[i]) for i in range(fold_train.shape[0])])\n",
    "flip_rot90 = np.array([np.rot90(fold_train[i],1) for i in range(fold_train.shape[0])])\n",
    "flip_rot180 = np.array([np.rot90(fold_train[i],2) for i in range(fold_train.shape[0])])\n",
    "flip_rot270 = np.array([np.rot90(fold_train[i],3) for i in range(fold_train.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_per_patch(session, graph, images, img_number, window_size, patch_size=16, stride=16):    \n",
    "    padding = (window_size-patch_size)//2\n",
    "    X = graph.get_tensor_by_name(\"X:0\")\n",
    "    y = graph.get_tensor_by_name(\"y:0\")\n",
    "    p = graph.get_tensor_by_name(\"p:0\")\n",
    "    #feed_dict ={X:X_train, p: 1}\n",
    "\n",
    "    #Now, access the op that you want to run. \n",
    "    op_to_restore = graph.get_tensor_by_name(\"out:0\")\n",
    "    \n",
    "    test_images = process(images, gt=False)\n",
    "    test_patches = np.array(img_crop(test_images[img_number-1], patch_size, patch_size, stride, padding))\n",
    "    \n",
    "    # datatest augmentation\n",
    "    flip_ud = np.array([np.flipud(test_patches[i]) for i in range(test_patches.shape[0])])\n",
    "    flip_lr = np.array([np.fliplr(test_patches[i]) for i in range(test_patches.shape[0])])\n",
    "    flip_rot90 = np.array([np.rot90(test_patches[i],1) for i in range(test_patches.shape[0])])\n",
    "    flip_rot180 = np.array([np.rot90(test_patches[i],2) for i in range(test_patches.shape[0])])\n",
    "    flip_rot270 = np.array([np.rot90(test_patches[i],3) for i in range(test_patches.shape[0])])\n",
    "    \n",
    "    \n",
    "    \n",
    "    if img_number==4:\n",
    "        print(test_patches.min(), test_patches.max())\n",
    "    \n",
    "    \n",
    "    Z = session.run(op_to_restore, feed_dict={X: test_patches, p: 1})\n",
    "    \n",
    "    # datatest augmentation prediction\n",
    "    Z_ud = session.run(op_to_restore, feed_dict={X: flip_ud, p: 1})\n",
    "    Z_lr = session.run(op_to_restore, feed_dict={X: flip_lr, p: 1})\n",
    "    print('jaja')\n",
    "    Z_rot90 = session.run(op_to_restore, feed_dict={X: flip_rot90, p: 1})\n",
    "    Z_rot180 = session.run(op_to_restore, feed_dict={X: flip_rot180, p: 1})\n",
    "    Z_rot270 = session.run(op_to_restore, feed_dict={X: flip_rot270, p: 1})\n",
    "    \n",
    "    \n",
    "    # Prediction\n",
    "    pred_fold = np.array([sigmoid(Z[i]) for i in range(test_patches.shape[0])])\n",
    "    pred_fold_ud = np.array([sigmoid(Z_ud[i]) for i in range(test_patches.shape[0])])\n",
    "    pred_fold_lr = np.array([sigmoid(Z_lr[i]) for i in range(test_patches.shape[0])])\n",
    "    pred_fold_rot90 = np.array([sigmoid(Z_rot90[i]) for i in range(test_patches.shape[0])])\n",
    "    pred_fold_rot180 = np.array([sigmoid(Z_rot180[i]) for i in range(test_patches.shape[0])])\n",
    "    pred_fold_rot270 = np.array([sigmoid(Z_rot270[i]) for i in range(test_patches.shape[0])])\n",
    "    \n",
    "    pred_mean = (pred_fold + pred_fold_ud + pred_fold_lr + pred_fold_rot90 + pred_fold_rot180 + pred_fold_rot270)/6\n",
    "    \n",
    "    prediction = (pred_mean>0.6)*1\n",
    "    \n",
    "    #print(Z.mean())\n",
    "    #prediction = Z.reshape(-1)\n",
    "    #prediction = np.array([sigmoid(i) for i in prediction])\n",
    "    #prediction = (prediction > 0.5) *1\n",
    "    #print(prediction)\n",
    "    \n",
    "    patch_size = 16\n",
    "    nb = 0\n",
    "    print(\"Processing \" + str(img_number-1))\n",
    "    for j in range(0, images[img_number-1].shape[1], patch_size):\n",
    "        for i in range(0, images[img_number-1].shape[0], patch_size):\n",
    "            label = int(prediction[nb])\n",
    "            nb += 1\n",
    "            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_restore_predict(filename_saver, images, window_size, to_submit_filename=None):\n",
    "    sess=tf.Session()    \n",
    "    #First let's load meta graph and restore weights\n",
    "    saver = tf.train.import_meta_graph('../models/' + filename_saver + '.ckpt.meta')\n",
    "    saver.restore(sess, '../models/' + filename_saver + '.ckpt')\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    with open(to_submit_filename, 'w') as f:\n",
    "        f.write('id,prediction\\n')\n",
    "        for nb_test in range(1, TEST_SIZE+1,1):\n",
    "            print(nb_test)\n",
    "            f.writelines('{}\\n'.format(s) for s in submission_per_patch(sess, graph, images, nb_test, window_size))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/model_10_epochs_54_window_size.ckpt\n",
      "1\n",
      "jaja\n",
      "Processing 0\n",
      "2\n",
      "jaja\n",
      "Processing 1\n",
      "3\n",
      "jaja\n",
      "Processing 2\n",
      "4\n",
      "-1.0 1.0\n",
      "jaja\n",
      "Processing 3\n",
      "5\n",
      "jaja\n",
      "Processing 4\n",
      "6\n",
      "jaja\n",
      "Processing 5\n",
      "7\n",
      "jaja\n",
      "Processing 6\n",
      "8\n",
      "jaja\n",
      "Processing 7\n",
      "9\n",
      "jaja\n",
      "Processing 8\n",
      "10\n",
      "jaja\n",
      "Processing 9\n",
      "11\n",
      "jaja\n",
      "Processing 10\n",
      "12\n",
      "jaja\n",
      "Processing 11\n",
      "13\n",
      "jaja\n",
      "Processing 12\n",
      "14\n",
      "jaja\n",
      "Processing 13\n",
      "15\n",
      "jaja\n",
      "Processing 14\n",
      "16\n",
      "jaja\n",
      "Processing 15\n",
      "17\n",
      "jaja\n",
      "Processing 16\n",
      "18\n",
      "jaja\n",
      "Processing 17\n",
      "19\n",
      "jaja\n",
      "Processing 18\n",
      "20\n",
      "jaja\n",
      "Processing 19\n",
      "21\n",
      "jaja\n",
      "Processing 20\n",
      "22\n",
      "jaja\n",
      "Processing 21\n",
      "23\n",
      "jaja\n",
      "Processing 22\n",
      "24\n",
      "jaja\n",
      "Processing 23\n",
      "25\n",
      "jaja\n",
      "Processing 24\n",
      "26\n",
      "jaja\n",
      "Processing 25\n",
      "27\n",
      "jaja\n",
      "Processing 26\n",
      "28\n",
      "jaja\n",
      "Processing 27\n",
      "29\n",
      "jaja\n",
      "Processing 28\n",
      "30\n",
      "jaja\n",
      "Processing 29\n",
      "31\n",
      "jaja\n",
      "Processing 30\n",
      "32\n",
      "jaja\n",
      "Processing 31\n",
      "33\n",
      "jaja\n",
      "Processing 32\n",
      "34\n",
      "jaja\n",
      "Processing 33\n",
      "35\n",
      "jaja\n",
      "Processing 34\n",
      "36\n",
      "jaja\n",
      "Processing 35\n",
      "37\n",
      "jaja\n",
      "Processing 36\n",
      "38\n",
      "jaja\n",
      "Processing 37\n",
      "39\n",
      "jaja\n",
      "Processing 38\n",
      "40\n",
      "jaja\n",
      "Processing 39\n",
      "41\n",
      "jaja\n",
      "Processing 40\n",
      "42\n",
      "jaja\n",
      "Processing 41\n",
      "43\n",
      "jaja\n",
      "Processing 42\n",
      "44\n",
      "jaja\n",
      "Processing 43\n",
      "45\n",
      "jaja\n",
      "Processing 44\n",
      "46\n",
      "jaja\n",
      "Processing 45\n",
      "47\n",
      "jaja\n",
      "Processing 46\n",
      "48\n",
      "jaja\n",
      "Processing 47\n",
      "49\n",
      "jaja\n",
      "Processing 48\n",
      "50\n",
      "jaja\n",
      "Processing 49\n"
     ]
    }
   ],
   "source": [
    "tf_restore_predict('model_10_epochs_54_window_size', images, 54, 'submission_10_epochs_54_window_size_test_augmentation_threshold60.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_per_patch(session, graph, session2, graph2, images, img_number, window_size, window_size2, patch_size=16, stride=16):    \n",
    "    \n",
    "    # Full graph\n",
    "    padding = (window_size-patch_size)//2\n",
    "    X = graph.get_tensor_by_name(\"X:0\")\n",
    "    y = graph.get_tensor_by_name(\"y:0\")\n",
    "    p = graph.get_tensor_by_name(\"p:0\")\n",
    "    #feed_dict ={X:X_train, p: 1}\n",
    "\n",
    "    #Now, access the op that you want to run. \n",
    "    op_to_restore = graph.get_tensor_by_name(\"out:0\")\n",
    "    \n",
    "    test_images = process(images, gt=False)\n",
    "    test_patches = np.array(img_crop(test_images[img_number-1], patch_size, patch_size, stride, padding))\n",
    "    \n",
    "    # datatest augmentation\n",
    "    flip_ud = np.array([np.flipud(test_patches[i]) for i in range(test_patches.shape[0])])\n",
    "    flip_lr = np.array([np.fliplr(test_patches[i]) for i in range(test_patches.shape[0])])\n",
    "    flip_rot90 = np.array([np.rot90(test_patches[i],1) for i in range(test_patches.shape[0])])\n",
    "    flip_rot180 = np.array([np.rot90(test_patches[i],2) for i in range(test_patches.shape[0])])\n",
    "    flip_rot270 = np.array([np.rot90(test_patches[i],3) for i in range(test_patches.shape[0])])\n",
    "    \n",
    "    \n",
    "    \n",
    "    if img_number==4:\n",
    "        print(test_patches.min(), test_patches.max())\n",
    "    \n",
    "    \n",
    "    Z = session.run(op_to_restore, feed_dict={X: test_patches, p: 1})\n",
    "    \n",
    "    # datatest augmentation prediction\n",
    "    Z_ud = session.run(op_to_restore, feed_dict={X: flip_ud, p: 1})\n",
    "    Z_lr = session.run(op_to_restore, feed_dict={X: flip_lr, p: 1})\n",
    "    print('jaja')\n",
    "    Z_rot90 = session.run(op_to_restore, feed_dict={X: flip_rot90, p: 1})\n",
    "    Z_rot180 = session.run(op_to_restore, feed_dict={X: flip_rot180, p: 1})\n",
    "    Z_rot270 = session.run(op_to_restore, feed_dict={X: flip_rot270, p: 1})\n",
    "    \n",
    "    \n",
    "    # Prediction\n",
    "    pred_fold = np.array([sigmoid(Z[i]) for i in range(test_patches.shape[0])])\n",
    "    pred_fold_ud = np.array([sigmoid(Z_ud[i]) for i in range(test_patches.shape[0])])\n",
    "    pred_fold_lr = np.array([sigmoid(Z_lr[i]) for i in range(test_patches.shape[0])])\n",
    "    pred_fold_rot90 = np.array([sigmoid(Z_rot90[i]) for i in range(test_patches.shape[0])])\n",
    "    pred_fold_rot180 = np.array([sigmoid(Z_rot180[i]) for i in range(test_patches.shape[0])])\n",
    "    pred_fold_rot270 = np.array([sigmoid(Z_rot270[i]) for i in range(test_patches.shape[0])])\n",
    "    \n",
    "    # Full graph\n",
    "    padding2 = (window_size2-patch_size)//2\n",
    "    X = graph2.get_tensor_by_name(\"X:0\")\n",
    "    y = graph2.get_tensor_by_name(\"y:0\")\n",
    "    p = graph2.get_tensor_by_name(\"p:0\")\n",
    "    #feed_dict ={X:X_train, p: 1}\n",
    "\n",
    "    #Now, access the op that you want to run. \n",
    "    op_to_restore = graph2.get_tensor_by_name(\"out:0\")\n",
    "    \n",
    "    #test_images = process(images, gt=False)\n",
    "    test_patches = np.array(img_crop(test_images[img_number-1], patch_size, patch_size, stride, padding2))\n",
    "    \n",
    "    # datatest augmentation\n",
    "    flip_ud2 = np.array([np.flipud(test_patches[i]) for i in range(test_patches.shape[0])])\n",
    "    flip_lr2 = np.array([np.fliplr(test_patches[i]) for i in range(test_patches.shape[0])])\n",
    "    flip_rot902 = np.array([np.rot90(test_patches[i],1) for i in range(test_patches.shape[0])])\n",
    "    flip_rot1802 = np.array([np.rot90(test_patches[i],2) for i in range(test_patches.shape[0])])\n",
    "    flip_rot2702 = np.array([np.rot90(test_patches[i],3) for i in range(test_patches.shape[0])])\n",
    "    \n",
    "    \n",
    "    \n",
    "    if img_number==4:\n",
    "        print(test_patches.min(), test_patches.max())\n",
    "    \n",
    "    \n",
    "    Z2 = session2.run(op_to_restore, feed_dict={X: test_patches, p: 1})\n",
    "    \n",
    "    # datatest augmentation prediction\n",
    "    Z_ud2 = session2.run(op_to_restore, feed_dict={X: flip_ud2, p: 1})\n",
    "    Z_lr2 = session2.run(op_to_restore, feed_dict={X: flip_lr2, p: 1})\n",
    "    print('jaja')\n",
    "    Z_rot902 = session2.run(op_to_restore, feed_dict={X: flip_rot902, p: 1})\n",
    "    Z_rot1802 = session2.run(op_to_restore, feed_dict={X: flip_rot1802, p: 1})\n",
    "    Z_rot2702 = session2.run(op_to_restore, feed_dict={X: flip_rot2702, p: 1})\n",
    "    \n",
    "    \n",
    "    # Prediction\n",
    "    pred_fold2 = np.array([sigmoid(Z2[i]) for i in range(test_patches.shape[0])])\n",
    "    pred_fold_ud2 = np.array([sigmoid(Z_ud2[i]) for i in range(test_patches.shape[0])])\n",
    "    pred_fold_lr2 = np.array([sigmoid(Z_lr2[i]) for i in range(test_patches.shape[0])])\n",
    "    pred_fold_rot902 = np.array([sigmoid(Z_rot902[i]) for i in range(test_patches.shape[0])])\n",
    "    pred_fold_rot1802 = np.array([sigmoid(Z_rot1802[i]) for i in range(test_patches.shape[0])])\n",
    "    pred_fold_rot2702 = np.array([sigmoid(Z_rot2702[i]) for i in range(test_patches.shape[0])])\n",
    "    \n",
    "    pred_mean = (pred_fold + pred_fold_ud + pred_fold_lr + pred_fold_rot90 + pred_fold_rot180 + pred_fold_rot270 + pred_fold2 + pred_fold_ud2 + pred_fold_lr2 + pred_fold_rot902 + pred_fold_rot1802 + pred_fold_rot2702)/12\n",
    "    \n",
    "    prediction = (pred_mean>0.6)*1\n",
    "    \n",
    "    #print(Z.mean())\n",
    "    #prediction = Z.reshape(-1)\n",
    "    #prediction = np.array([sigmoid(i) for i in prediction])\n",
    "    #prediction = (prediction > 0.5) *1\n",
    "    #print(prediction)\n",
    "    \n",
    "    patch_size = 16\n",
    "    nb = 0\n",
    "    print(\"Processing \" + str(img_number-1))\n",
    "    for j in range(0, images[img_number-1].shape[1], patch_size):\n",
    "        for i in range(0, images[img_number-1].shape[0], patch_size):\n",
    "            label = int(prediction[nb])\n",
    "            nb += 1\n",
    "            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_restore_predict(filename_saver, images, window_size, window_size2, filename_saver2, to_submit_filename=None):\n",
    "    sess=tf.Session()    \n",
    "    #First let's load meta graph and restore weights\n",
    "    saver = tf.train.import_meta_graph('../models/' + filename_saver + '.ckpt.meta')\n",
    "    saver.restore(sess, '../models/' + filename_saver + '.ckpt')\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    \n",
    "    sess2=tf.Session()    \n",
    "    #First let's load meta graph and restore weights\n",
    "    saver2 = tf.train.import_meta_graph('../models/' + filename_saver2 + '.ckpt.meta')\n",
    "    saver2.restore(sess2, '../models/' + filename_saver2 + '.ckpt')\n",
    "    graph2 = tf.get_default_graph()\n",
    "    \n",
    "    with open(to_submit_filename, 'w') as f:\n",
    "        f.write('id,prediction\\n')\n",
    "        for nb_test in range(1, TEST_SIZE+1,1):\n",
    "            print(nb_test)\n",
    "            f.writelines('{}\\n'.format(s) for s in submission_per_patch(sess, graph, sess2, graph2, images, nb_test, window_size, window_size2 ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/model_10_epochs_54_window_size.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../models/model_10_epochs_32_window_size.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [2304,1] rhs shape= [1024,1]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable, save/RestoreV2)]]\n\nCaused by op 'save/Assign', defined at:\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-144-b54f5d28a69f>\", line 1, in <module>\n    x_TEST, y_TEST, gt_TEST = cnn_TEST.train(augmented_train, augmented_ground_truth, saver_filename='model_10_epochs_54_window_size', number_epochs=10)\n  File \"<ipython-input-142-5e772b69743d>\", line 145, in train\n    saver = tf.train.Saver()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1281, in __init__\n    self.build()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [2304,1] rhs shape= [1024,1]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable, save/RestoreV2)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [2304,1] rhs shape= [1024,1]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable, save/RestoreV2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1724\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1725\u001b[1;33m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1726\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [2304,1] rhs shape= [1024,1]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable, save/RestoreV2)]]\n\nCaused by op 'save/Assign', defined at:\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-144-b54f5d28a69f>\", line 1, in <module>\n    x_TEST, y_TEST, gt_TEST = cnn_TEST.train(augmented_train, augmented_ground_truth, saver_filename='model_10_epochs_54_window_size', number_epochs=10)\n  File \"<ipython-input-142-5e772b69743d>\", line 145, in train\n    saver = tf.train.Saver()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1281, in __init__\n    self.build()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [2304,1] rhs shape= [1024,1]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable, save/RestoreV2)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-3a930bf7d310>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf_restore_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_10_epochs_54_window_size'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m54\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model_10_epochs_32_window_size'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'submission_10_epochs_54_32_window_size_test_augmentation_threshold60.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-151-9a471c84a950>\u001b[0m in \u001b[0;36mtf_restore_predict\u001b[1;34m(filename_saver, images, window_size, window_size2, filename_saver2, to_submit_filename)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#First let's load meta graph and restore weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0msaver2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../models/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename_saver2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.ckpt.meta'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0msaver2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'../models/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename_saver2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.ckpt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mgraph2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1757\u001b[0m       \u001b[1;31m# We add a more reasonable error message here to help users (b/110263146)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1758\u001b[0m       raise _wrap_restore_error_with_msg(\n\u001b[1;32m-> 1759\u001b[1;33m           err, \"a mismatch between the current graph and the graph\")\n\u001b[0m\u001b[0;32m   1760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1761\u001b[0m   def _restore_from_object_based_checkpoint(self, sess, save_path,\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [2304,1] rhs shape= [1024,1]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable, save/RestoreV2)]]\n\nCaused by op 'save/Assign', defined at:\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-144-b54f5d28a69f>\", line 1, in <module>\n    x_TEST, y_TEST, gt_TEST = cnn_TEST.train(augmented_train, augmented_ground_truth, saver_filename='model_10_epochs_54_window_size', number_epochs=10)\n  File \"<ipython-input-142-5e772b69743d>\", line 145, in train\n    saver = tf.train.Saver()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1281, in __init__\n    self.build()\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Brice\\Anaconda3\\envs\\myenvironment\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [2304,1] rhs shape= [1024,1]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable, save/RestoreV2)]]\n"
     ]
    }
   ],
   "source": [
    "tf_restore_predict('model_10_epochs_54_window_size', images, 54, 32, 'model_10_epochs_32_window_size' , 'submission_10_epochs_54_32_window_size_test_augmentation_threshold60.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
